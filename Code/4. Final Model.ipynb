{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "062770fe",
   "metadata": {},
   "source": [
    "# Data Dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad6b588a",
   "metadata": {},
   "source": [
    "|Feature|Type|Description|\n",
    "|---|---|---|\n",
    "|Product_Code|*string*|The product name encoded|\n",
    "|Warehouse|*string*|Warehouse ID|\n",
    "|Product_Category|*string*|Product category of each product|\n",
    "|Date|*string*|The date customer needs the product|\n",
    "|Order_Demand|*string*|Order quantity|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "52f64c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from numpy import array\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59efff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924272, 5)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file and display shape.\n",
    "df = pd.read_csv('../Data_Historical/df2.csv').iloc[:,1:]\n",
    "\n",
    "# Get list of product codes.\n",
    "products = df['Product_Code'].unique()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5487f4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product_0965</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_006</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product_1724</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_003</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product_1521</td>\n",
       "      <td>Whse_S</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product_1521</td>\n",
       "      <td>Whse_S</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product_1507</td>\n",
       "      <td>Whse_C</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Code Warehouse Product_Category        Date  Order_Demand\n",
       "0  Product_0965    Whse_A     Category_006  2011-01-08             2\n",
       "1  Product_1724    Whse_A     Category_003  2011-05-31           108\n",
       "2  Product_1521    Whse_S     Category_019  2011-06-24         85000\n",
       "3  Product_1521    Whse_S     Category_019  2011-06-24          7000\n",
       "4  Product_1507    Whse_C     Category_019  2011-09-02          1250"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "13a6bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and resample order demand.\n",
    "def get_product(data,product_code):\n",
    "    df_init = data[data['Product_Code']==product_code]\n",
    "    df_init['Date'] = pd.to_datetime(df_init['Date'])\n",
    "    df_init = df_init.set_index('Date')\n",
    "    df_out = pd.DataFrame(df_init['Order_Demand'].resample('W').sum())\n",
    "    df_out.rename(columns={'Order_Demand':'demand'+'_'+product_code[-4:]}, inplace=True)\n",
    "    return df_out\n",
    "\n",
    "# split a univariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    " X, y = list(), list()\n",
    " \n",
    " for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + n_steps\n",
    "    \n",
    "    # check if we are beyond the sequence\n",
    "    if end_ix > len(sequence)-1:\n",
    "        break\n",
    "    \n",
    "    # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    " return array(X), array(y)\n",
    "\n",
    "# Function to apply standard scaling to input.\n",
    "def scale(X_train): #, X_test\n",
    " # fit scaler\n",
    " scaler = StandardScaler()\n",
    " # Fit & transform train\n",
    " X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    " # Transform test\n",
    " #X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    " return scaler, X_train #, X_test\n",
    "\n",
    "# Function to reshape and scale the previous week's sales.\n",
    "def reshape_scale(y0):\n",
    "    # Reshape to (1,1,1)\n",
    "    wk0 = y0[-1:].reshape((1,1,n_features))\n",
    "    # Transform to standard scaling\n",
    "    wk0 = scaler.transform(wk0.reshape(-1, wk0.shape[-1])).reshape(wk0.shape)\n",
    "    return wk0\n",
    "\n",
    "# LSTM Model.\n",
    "def fit_lstm (X, y):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True,  input_shape=(n_steps, n_features))) \n",
    "    model.add(LSTM(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=.001), loss='mse')\n",
    "    lstm = model.fit(X, y, epochs=800, verbose=0, batch_size=32)\n",
    "    return model, lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6a2dcef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the model and predictions\n",
    "def run(df, product):\n",
    "    n_steps = 1\n",
    "    n_features = 1\n",
    "    preds = list()   \n",
    "    # Create dataframe of Product\n",
    "    prod = get_product(df, product)\n",
    "    # define input sequence\n",
    "    raw_seq = prod.iloc[:,0]\n",
    "    # split into samples\n",
    "    X, y = split_sequence(raw_seq, n_steps)\n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    # Standard scaling X\n",
    "    scaler, X_scaled = scale(X)\n",
    "    model, lstm = fit_lstm(X_scaled, y)\n",
    "    wk0 = reshape_scale(y[-1:])\n",
    "    # Predict Week 1\n",
    "    predwk1 = model.predict(wk0)\n",
    "    preds.append(predwk1)\n",
    "    # Predict Week 2\n",
    "    predwk2 = model.predict(reshape_scale(predwk1))\n",
    "    preds.append(predwk2)\n",
    "    # Predict Week 3\n",
    "    predwk3 = model.predict(reshape_scale(predwk2))\n",
    "    preds.append(predwk3)\n",
    "    # Predict Week 4\n",
    "    predwk4 = model.predict(reshape_scale(predwk3))\n",
    "    preds.append(predwk4)\n",
    "    # Reshape predictions to 2 D\n",
    "    reshaped = np.reshape(preds, (4,))\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5a4b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = prod_1359['demand_1359']\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# Standard scaling X\n",
    "scaler, X_scaled = scale(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60dd493b",
   "metadata": {},
   "source": [
    "# Final Model - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b181ef7",
   "metadata": {},
   "source": [
    "model, lstm = fit_lstm(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d96c5",
   "metadata": {},
   "source": [
    "wk0 = reshape_scale(y[-1:])\n",
    "predwk1 = model.predict(wk0)\n",
    "predwk2 = model.predict(reshape_scale(predwk1))\n",
    "predwk3 = model.predict(reshape_scale(predwk2))\n",
    "predwk4 = model.predict(reshape_scale(predwk3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffa8d0",
   "metadata": {},
   "source": [
    "prod_list = list()\n",
    "preds = list()\n",
    "for product in products:\n",
    "    # Create dataframe of Product\n",
    "    prod = get_product(df, product)\n",
    "    # define input sequence\n",
    "    raw_seq = prod.iloc[:,0]\n",
    "    # split into samples\n",
    "    X, y = split_sequence(raw_seq, n_steps)\n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    # Standard scaling X\n",
    "    scaler, X_scaled = scale(X)\n",
    "    model, lstm = fit_lstm(X_scaled, y)\n",
    "    wk0 = reshape_scale(y[-1:])\n",
    "    predwk1 = model.predict(wk0)\n",
    "    prod_list.append(product)\n",
    "    preds.append(predwk1)\n",
    "    predwk2 = model.predict(reshape_scale(predwk1))\n",
    "    prod_list.append(product)\n",
    "    preds.append(predwk2)\n",
    "    predwk3 = model.predict(reshape_scale(predwk2))\n",
    "    prod_list.append(product)\n",
    "    preds.append(predwk3)\n",
    "    predwk4 = model.predict(reshape_scale(predwk3))\n",
    "    prod_list.append(product)\n",
    "    preds.append(predwk4)\n",
    "    print (product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26f4169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeonice\\AppData\\Local\\Temp\\ipykernel_16572\\1616143787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_init['Date'] = pd.to_datetime(df_init['Date'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zeonice\\Desktop\\Capstone\\Code\\4. Final Model.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m product \u001b[39min\u001b[39;00m products[\u001b[39m0\u001b[39m:\u001b[39m1080\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     predictions \u001b[39m=\u001b[39m run(df, product)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df_prod \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({product:predictions})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([dfs, df_prod],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Zeonice\\Desktop\\Capstone\\Code\\4. Final Model.ipynb Cell 13\u001b[0m in \u001b[0;36mrun\u001b[1;34m(df, product)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Standard scaling X\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m scaler, X_scaled \u001b[39m=\u001b[39m scale(X)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model, lstm \u001b[39m=\u001b[39m fit_lstm(X_scaled, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m wk0 \u001b[39m=\u001b[39m reshape_scale(y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Predict Week 1\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Zeonice\\Desktop\\Capstone\\Code\\4. Final Model.ipynb Cell 13\u001b[0m in \u001b[0;36mfit_lstm\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m.001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m lstm \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zeonice/Desktop/Capstone/Code/4.%20Final%20Model.ipynb#X51sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, lstm\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:1641\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1639\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1640\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1641\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1642\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m         ):\n\u001b[0;32m   1649\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1371\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1372\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1373\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1374\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[0;32m   1376\u001b[0m )\n\u001b[0;32m   1378\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:639\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    640\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    641\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:727\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \n\u001b[0;32m    720\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 727\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[0;32m    728\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:706\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    704\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    705\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    709\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    710\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    712\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    713\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    714\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:696\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    695\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 696\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    698\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    699\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:580\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    579\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    581\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    582\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    583\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs = pd.DataFrame()\n",
    "for product in products[0:1080]:\n",
    "    predictions = run(df, product)\n",
    "    df_prod = pd.DataFrame({product:predictions})\n",
    "    dfs = pd.concat([dfs, df_prod],axis=1)\n",
    "dfs.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0e68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e19db1e9da599290b8ff42b0f8e8323be965d18c8fa7c16db7240545f8fbedb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
